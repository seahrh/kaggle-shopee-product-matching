{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23bcb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scml\n",
    "import mylib\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5950c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scml.seed_everything()\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5570d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'efficientnetb0'\n",
    "CONF = {\n",
    "    'efficientnetb0': {\n",
    "        'resolution': 224,\n",
    "        'output_size': 1280,\n",
    "    },\n",
    "    'efficientnetb1': {\n",
    "        'resolution': 240,\n",
    "        'output_size': 0,\n",
    "    },\n",
    "    'efficientnetb2': {\n",
    "        'resolution': 260,\n",
    "        'output_size': 1408,\n",
    "    },\n",
    "    'efficientnetb3': {\n",
    "        'resolution': 300,\n",
    "        'output_size': 1536,\n",
    "    },\n",
    "    'efficientnetb4': {\n",
    "        'resolution': 380,\n",
    "        'output_size': 1792,\n",
    "    },\n",
    "    'efficientnetb5': {\n",
    "        'resolution': 456,\n",
    "        'output_size': 2048,\n",
    "    },\n",
    "    'efficientnetb6': {\n",
    "        'resolution': 528,\n",
    "        'output_size': 2304,\n",
    "    },\n",
    "    'efficientnetb7': {\n",
    "        'resolution': 600,\n",
    "        'output_size': 2560,\n",
    "    },\n",
    "}\n",
    "INPUT_SHAPE = (CONF[MODEL]['resolution'], CONF[MODEL]['resolution'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1427f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=11014\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      " 5   target       34250 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.csv\", engine=\"c\", low_memory=False)\n",
    "train[\"target\"] = mylib.target_label(train)\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "train[\"label_group\"] = le.fit_transform(train['label_group'])\n",
    "n_classes=len(le.classes_)\n",
    "print(f\"n_classes={n_classes}\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f25bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "      <td>7572</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>[train_2288590299, train_3803689425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi</td>\n",
       "      <td>10509</td>\n",
       "      <td>[train_2406599165, train_3342059966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0                                                                           Paper Bag Victoria Secret   \n",
       "1                                        Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE   \n",
       "2                                                         Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi   \n",
       "4                                                                   Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "\n",
       "   label_group                                target  \n",
       "0          666   [train_129225211, train_2278313361]  \n",
       "1         7572  [train_3386243561, train_3423213080]  \n",
       "2         6172  [train_2288590299, train_3803689425]  \n",
       "3        10509  [train_2406599165, train_3342059966]  \n",
       "4         9425   [train_3369186413, train_921438619]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e30601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_gen(\n",
    "    dataframe,\n",
    "    directory,\n",
    "    target_size,\n",
    "    batch_size,\n",
    "    mode,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label_group\"\n",
    "):\n",
    "    dtype = np.float32\n",
    "    rescale = 1./255\n",
    "    interpolation = \"nearest\"\n",
    "    data_format = \"channels_last\"\n",
    "    shuffle = False\n",
    "    idg = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=rescale,\n",
    "        data_format=data_format,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    if mode == \"train\":\n",
    "        shuffle = True\n",
    "        idg = keras.preprocessing.image.ImageDataGenerator(\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            rescale=rescale,\n",
    "            data_format=data_format,\n",
    "            dtype=dtype\n",
    "        )\n",
    "    g = idg.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        directory=directory,\n",
    "        target_size=target_size,\n",
    "        color_mode=color_mode,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        class_mode=class_mode,\n",
    "        interpolation=interpolation,\n",
    "    )\n",
    "    while True:\n",
    "        x, y = g.next()\n",
    "        yield [x, y], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf2c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_GENERATOR = False\n",
    "if CHECK_GENERATOR:\n",
    "    spl = sklearn.model_selection.GroupKFold(n_splits=3)\n",
    "    x = train\n",
    "    y = train[\"label_group\"]\n",
    "    groups = train[\"label_group\"]\n",
    "    for ti, vi in spl.split(x, y, groups):\n",
    "        train_gen = _data_gen(\n",
    "            dataframe=train.iloc[ti],\n",
    "            directory=\"input/train_images\",\n",
    "            target_size=INPUT_SHAPE[:2],\n",
    "            batch_size=32,\n",
    "            mode=\"train\"\n",
    "        )\n",
    "        val_gen = _data_gen(\n",
    "            dataframe=train.iloc[vi],\n",
    "            directory=\"input/train_images\",\n",
    "            target_size=INPUT_SHAPE[:2],\n",
    "            batch_size=32,\n",
    "            mode=\"val\"\n",
    "        )\n",
    "        n = len(ti)\n",
    "        i = 0\n",
    "        for [x, y1], y2 in tqdm(train_gen):\n",
    "            i += x.shape[0]\n",
    "            if i >= n:\n",
    "                break\n",
    "        print(f\"len(train_gen)={i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c798a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aaca7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model(\n",
    "    pretrained,\n",
    "    n_classes: int,\n",
    "    lr: float,\n",
    "    input_shape: Tuple[int, int, int],\n",
    "    dtype=np.float32\n",
    "):\n",
    "    pretrained.trainable = False\n",
    "    #kernel_initializer = keras.initializers.he_normal()\n",
    "    #kernel_regularizer = keras.regularizers.l2(0.01)\n",
    "    image_input = keras.layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    label_input = keras.layers.Input(shape=(), name=\"label_input\")\n",
    "    x = pretrained(image_input)\n",
    "    x = keras.layers.Dense(pretrained.output_shape[1], activation=\"relu\")(x)\n",
    "    x = keras.layers.LayerNormalization(name=\"embedding_output\")(x)\n",
    "    x = ArcMarginProduct(\n",
    "        n_classes=n_classes, \n",
    "        s=30, \n",
    "        m=0.5, \n",
    "        name='head/arc_margin', \n",
    "        dtype=dtype\n",
    "    )([x, label_input])\n",
    "    output = tf.keras.layers.Softmax(dtype=dtype)(x)\n",
    "    model = tf.keras.models.Model(inputs = [image_input, label_input], outputs = [output])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "    sca = keras.metrics.SparseCategoricalAccuracy()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[sca])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c7d8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)     (None, 1280)         4049571     image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1280)         1639680     efficientnetb0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_output (LayerNormaliz (None, 1280)         2560        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "label_input (InputLayer)        [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProdu (None, 11014)        14097920    embedding_output[0][0]           \n",
      "                                                                 label_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 11014)        0           head/arc_margin[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 19,789,731\n",
      "Trainable params: 15,740,160\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained = keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    pooling=\"max\",\n",
    "    weights=\"pretrained/efficientnet/efficientnetb0_notop.h5\"\n",
    ")\n",
    "model = _model(\n",
    "    pretrained=pretrained,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    n_classes=n_classes,\n",
    "    lr=1e-3,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cdfeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _callbacks(patience: int):\n",
    "    return [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=patience, verbose=1\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb97ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObjective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        splitter,\n",
    "        groups,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        patience: int,\n",
    "        job_dir: str,\n",
    "        lr: Tuple[float, float],\n",
    "        n_classes: int,\n",
    "        input_shape: Tuple[int, int, int],\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.splitter = splitter\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.job_dir = job_dir\n",
    "        self.groups = groups\n",
    "        self.lr = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.input_shape = input_shape\n",
    "        self.history: List[Dict[str, Union[str, int, float]]] = []\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        hist = {\n",
    "            \"trial_id\": trial.number,\n",
    "            \"learning_rate\": trial.suggest_loguniform(\n",
    "                \"learning_rate\", self.lr[0], self.lr[1]\n",
    "            ),\n",
    "        }\n",
    "        scores = []\n",
    "        for fold, (ti, vi) in enumerate(\n",
    "            self.splitter.split(self.df.index, None, groups=self.groups)\n",
    "        ):\n",
    "            train_gen = _data_gen(\n",
    "                dataframe=self.df.iloc[ti],\n",
    "                directory=\"input/train_images\",\n",
    "                target_size=self.input_shape[:2],\n",
    "                batch_size=self.batch_size,\n",
    "                mode=\"train\"\n",
    "            )\n",
    "            val_gen = _data_gen(\n",
    "                dataframe=self.df.iloc[vi],\n",
    "                directory=\"input/train_images\",\n",
    "                target_size=self.input_shape[:2],\n",
    "                batch_size=self.batch_size,\n",
    "                mode=\"val\"\n",
    "            )\n",
    "            pretrained = keras.applications.EfficientNetB0(\n",
    "                include_top=False,\n",
    "                input_shape=self.input_shape,\n",
    "                pooling=\"max\",\n",
    "                weights=\"pretrained/efficientnet/efficientnetb0_notop.h5\"\n",
    "            )\n",
    "            model = _model(\n",
    "                pretrained=pretrained,\n",
    "                input_shape=self.input_shape,\n",
    "                n_classes=self.n_classes,\n",
    "                lr=hist[\"learning_rate\"],\n",
    "            )\n",
    "            #model.summary()\n",
    "            directory = f\"{self.job_dir}/trial_{hist['trial_id']}/fold_{fold}\"\n",
    "            history = model.fit(\n",
    "                train_gen,\n",
    "                epochs=self.epochs,\n",
    "                steps_per_epoch=len(ti) / self.batch_size + 1,\n",
    "                validation_steps=len(vi) / self.batch_size + 1,\n",
    "                validation_data=val_gen,\n",
    "                callbacks=_callbacks(self.patience),\n",
    "            )\n",
    "            #y_pred = model.predict(x_val, batch_size=self.batch_size)\n",
    "            #score = metrics.mean_squared_error(y_val, y_pred, squared=False)\n",
    "            #print(repr(history.history))\n",
    "            score = history.history[\"val_sparse_categorical_accuracy\"][-1]\n",
    "            #log.info(f\"score={score:.4f}, fold={fold}, trial={hist['trial_id']}\")\n",
    "            print(f\"score={score:.4f}, fold={fold}, trial={hist['trial_id']}\")\n",
    "            hist[f\"fold_{fold}_score\"] = score\n",
    "            scores.append(score)\n",
    "            del model\n",
    "            gc.collect()\n",
    "        hist[\"score_mean\"] = np.mean(scores)\n",
    "        hist[\"score_std\"] = np.std(scores)\n",
    "        hist[\"score_worst\"] = max(scores)\n",
    "        self.history.append(hist)\n",
    "        return hist[\"score_worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a0342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-30 15:29:40,450]\u001b[0m A new study created in memory with name: no-name-be467479-04db-4722-86d5-cb298bbf2de9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17125 validated image filenames.\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "obj = MyObjective(\n",
    "    df=train,\n",
    "    splitter=sklearn.model_selection.GroupKFold(n_splits=2),\n",
    "    groups=train[\"label_group\"],\n",
    "    epochs=2,\n",
    "    batch_size=512,\n",
    "    patience=2,\n",
    "    job_dir=\"tmp\",\n",
    "    lr=(1e-3, 1e-3),\n",
    "    n_classes=n_classes,\n",
    "    input_shape=INPUT_SHAPE,\n",
    ")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(obj, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1236c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
