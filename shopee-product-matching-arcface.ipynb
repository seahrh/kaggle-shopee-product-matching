{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS=1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(f\"REPLICAS={strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_KERNEL_RUN_TYPE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "IS_KAGGLE = KAGGLE_KERNEL_RUN_TYPE != 'Localhost'\n",
    "INPUT = 'input'\n",
    "DATA = INPUT\n",
    "OUTPUT = 'output'\n",
    "RESOURCE_DIR = '.'\n",
    "if IS_KAGGLE:\n",
    "    INPUT = '/kaggle/input'\n",
    "    DATA = f'{INPUT}/shopee-product-matching'\n",
    "    OUTPUT = '/kaggle/working'\n",
    "    RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'\n",
    "    sys.path.append(f'{INPUT}/sgcharts-ml/src')\n",
    "    sys.path.append(f\"{INPUT}/sentence-transformers/sentence-transformers-1.0.4\")\n",
    "    sys.path.append(f'{RESOURCE_DIR}/src')\n",
    "import mylib\n",
    "import scml\n",
    "from scml.nlp import strip_punctuation, to_ascii_str\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_SHAPE=(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'efficientnetb0'\n",
    "CONF = configparser.ConfigParser()\n",
    "CONF.read(f\"{RESOURCE_DIR}/app.ini\")\n",
    "resolution = int(CONF[MODEL][\"resolution\"])\n",
    "INPUT_SHAPE = (resolution, resolution, 3)\n",
    "print(f\"INPUT_SHAPE={INPUT_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=11014\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      " 5   target       34250 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{DATA}/train.csv\", engine=\"c\", low_memory=False)\n",
    "train[\"target\"] = mylib.target_label(train)\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "train[\"label_group\"] = le.fit_transform(train['label_group'])\n",
    "n_classes=len(le.classes_)\n",
    "print(f\"n_classes={n_classes}\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "      <td>7572</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>[train_2288590299, train_3803689425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi</td>\n",
       "      <td>10509</td>\n",
       "      <td>[train_2406599165, train_3342059966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0                                                                           Paper Bag Victoria Secret   \n",
       "1                                        Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE   \n",
       "2                                                         Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi   \n",
       "4                                                                   Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "\n",
       "   label_group                                target  \n",
       "0          666   [train_129225211, train_2278313361]  \n",
       "1         7572  [train_3386243561, train_3423213080]  \n",
       "2         6172  [train_2288590299, train_3803689425]  \n",
       "3        10509  [train_2406599165, train_3342059966]  \n",
       "4         9425   [train_3369186413, train_921438619]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_gen(\n",
    "    dataframe,\n",
    "    directory,\n",
    "    target_size,\n",
    "    batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label_group\"\n",
    "):\n",
    "    dtype = np.float32\n",
    "    rescale = 1./255\n",
    "    interpolation = \"nearest\"\n",
    "    data_format = \"channels_last\"\n",
    "    shuffle = True\n",
    "    idg = keras.preprocessing.image.ImageDataGenerator(\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        #horizontal_flip=True,\n",
    "        rescale=rescale,\n",
    "        data_format=data_format,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    g = idg.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        directory=directory,\n",
    "        target_size=target_size,\n",
    "        color_mode=color_mode,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        class_mode=class_mode,\n",
    "        interpolation=interpolation,\n",
    "    )\n",
    "    while True:\n",
    "        x, y = g.next()\n",
    "        yield [x, y], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model(\n",
    "    pretrained,\n",
    "    n_classes: int,\n",
    "    lr: float,\n",
    "    input_shape: Tuple[int, int, int],\n",
    "    dtype=np.float32\n",
    "):\n",
    "    pretrained.trainable = False\n",
    "    #kernel_initializer = keras.initializers.he_normal()\n",
    "    #kernel_regularizer = keras.regularizers.l2(0.01)\n",
    "    image_input = keras.layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    label_input = keras.layers.Input(shape=(), name=\"label_input\")\n",
    "    x = pretrained(image_input)\n",
    "    x = keras.layers.LayerNormalization()(x)\n",
    "    x = keras.layers.Dense(pretrained.output_shape[1], activation=\"relu\")(x)\n",
    "    x = keras.layers.LayerNormalization(name=\"embedding_output\")(x)\n",
    "    x = mylib.ArcMarginProduct(\n",
    "        n_classes=n_classes, \n",
    "        s=30, \n",
    "        m=0.5, \n",
    "        name='head/arc_margin', \n",
    "        dtype=dtype\n",
    "    )([x, label_input])\n",
    "    output = tf.keras.layers.Softmax(dtype=dtype)(x)\n",
    "    model = tf.keras.models.Model(inputs = [image_input, label_input], outputs = [output])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "    sca = keras.metrics.SparseCategoricalAccuracy()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[sca])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "image_input (InputLayer)                         [(None, 224, 224, 3)]            0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "efficientnetb0 (Functional)                      (None, 1280)                     4049571           image_input[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "layer_normalization (LayerNormalization)         (None, 1280)                     2560              efficientnetb0[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense (Dense)                                    (None, 1280)                     1639680           layer_normalization[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "embedding_output (LayerNormalization)            (None, 1280)                     2560              dense[0][0]                                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "label_input (InputLayer)                         [(None,)]                        0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProduct)               (None, 11014)                    14097920          embedding_output[0][0]                            \n",
      "                                                                                                    label_input[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "softmax (Softmax)                                (None, 11014)                    0                 head/arc_margin[0][0]                             \n",
      "======================================================================================================================================================\n",
      "Total params: 19,792,291\n",
      "Trainable params: 15,742,720\n",
      "Non-trainable params: 4,049,571\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained = mylib.efficient_net(\n",
    "    variant=MODEL,\n",
    "    pooling=\"avg\",\n",
    "    directory=f\"{RESOURCE_DIR}/pretrained/efficientnet\",\n",
    ")\n",
    "model = _model(\n",
    "    pretrained=pretrained,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    n_classes=n_classes,\n",
    "    lr=1e-3,\n",
    ")\n",
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _callbacks(patience: int, directory: str):\n",
    "    return [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"loss\", patience=patience, verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"{directory}/model.h5\",\n",
    "            monitor=\"loss\",\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObjective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        patience: int,\n",
    "        job_dir: str,\n",
    "        lr: Tuple[float, float],\n",
    "        n_classes: int,\n",
    "        input_shape: Tuple[int, int, int],\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.job_dir = job_dir\n",
    "        self.lr = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.input_shape = input_shape\n",
    "        self.history: List[Dict[str, Union[str, int, float]]] = []\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        hist = {\n",
    "            \"trial_id\": trial.number,\n",
    "            \"learning_rate\": trial.suggest_loguniform(\n",
    "                \"learning_rate\", self.lr[0], self.lr[1]\n",
    "            ),\n",
    "        }\n",
    "        train_gen = _data_gen(\n",
    "            dataframe=self.df,\n",
    "            directory=f\"{DATA}/train_images\",\n",
    "            target_size=self.input_shape[:2],\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        pretrained = mylib.efficient_net(\n",
    "            variant=MODEL,\n",
    "            pooling=\"avg\",\n",
    "            directory=f\"{RESOURCE_DIR}/pretrained/efficientnet\",\n",
    "        )\n",
    "        model = _model(\n",
    "            pretrained=pretrained,\n",
    "            input_shape=self.input_shape,\n",
    "            n_classes=self.n_classes,\n",
    "            lr=hist[\"learning_rate\"],\n",
    "        )\n",
    "        directory = f\"{self.job_dir}/trial_{hist['trial_id']}\"\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            epochs=self.epochs,\n",
    "            steps_per_epoch=len(self.df) / self.batch_size + 1,\n",
    "            #validation_steps=len(vi) / self.batch_size + 1,\n",
    "            #validation_data=val_gen,\n",
    "            callbacks=_callbacks(self.patience, directory=directory),\n",
    "            verbose=1\n",
    "        )\n",
    "        #y_pred = model.predict(x_val, batch_size=self.batch_size)\n",
    "        #score = metrics.mean_squared_error(y_val, y_pred, squared=False)\n",
    "        #print(repr(history.history))\n",
    "        score = history.history[\"sparse_categorical_accuracy\"][-1]\n",
    "        #log.info(f\"score={score:.4f}, fold={fold}, trial={hist['trial_id']}\")\n",
    "        print(f\"score={score:.4f}, trial={hist['trial_id']}\")\n",
    "        del model\n",
    "        gc.collect()\n",
    "        hist[\"score_worst\"] = score\n",
    "        self.history.append(hist)\n",
    "        return hist[\"score_worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-08 12:41:39,121]\u001b[0m A new study created in memory with name: no-name-226bdd81-7521-4547-81d2-0f5d31d58c35\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34250 validated image filenames.\n",
      "Epoch 1/40\n",
      "67/67 [==============================] - 3237s 48s/step - loss: 24.5915 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: loss improved from inf to 24.31868, saving model to output/trial_0/model.h5\n",
      "Epoch 2/40\n",
      "67/67 [==============================] - 2731s 40s/step - loss: 23.2401 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: loss improved from 24.31868 to 23.19616, saving model to output/trial_0/model.h5\n",
      "Epoch 3/40\n",
      "67/67 [==============================] - 3383s 50s/step - loss: 22.7323 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: loss improved from 23.19616 to 22.55634, saving model to output/trial_0/model.h5\n",
      "Epoch 4/40\n",
      "67/67 [==============================] - 3351s 49s/step - loss: 21.3055 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: loss improved from 22.55634 to 20.51913, saving model to output/trial_0/model.h5\n",
      "Epoch 5/40\n",
      "67/67 [==============================] - 2293s 34s/step - loss: 16.5985 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: loss improved from 20.51913 to 16.12255, saving model to output/trial_0/model.h5\n",
      "Epoch 6/40\n",
      "67/67 [==============================] - 2424s 36s/step - loss: 16.4320 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: loss did not improve from 16.12255\n",
      "Epoch 7/40\n",
      "67/67 [==============================] - 2458s 36s/step - loss: 16.3937 - sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: loss did not improve from 16.12255\n",
      "Epoch 00007: early stopping\n",
      "score=0.0000, trial=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-08 18:13:07,854]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.001}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "obj = MyObjective(\n",
    "    df=train,\n",
    "    epochs=40,\n",
    "    batch_size=512 * strategy.num_replicas_in_sync,  # B3: OOM if batch size > 128 \n",
    "    patience=2,\n",
    "    job_dir=OUTPUT,\n",
    "    lr=(1e-3, 1e-3),\n",
    "    n_classes=n_classes,\n",
    "    input_shape=INPUT_SHAPE,\n",
    ")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(obj, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>score_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_id  learning_rate  score_worst\n",
       "0         0          0.001          0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.DataFrame.from_records(obj.history)\n",
    "history.sort_values(\"score_worst\", ascending=False, inplace=True, ignore_index=True)\n",
    "history.to_csv(f\"{OUTPUT}/cv.csv\", index=False)\n",
    "history.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
