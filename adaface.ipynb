{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4f2ffaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scml\n",
    "import mylib\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c8dfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scml.seed_everything()\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9cbf6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'efficientnetb3'\n",
    "CONF = {\n",
    "    'efficientnetb0': {\n",
    "        'resolution': 224,\n",
    "        'output_size': 1280,\n",
    "    },\n",
    "    'efficientnetb1': {\n",
    "        'resolution': 240,\n",
    "        'output_size': 0,\n",
    "    },\n",
    "    'efficientnetb2': {\n",
    "        'resolution': 260,\n",
    "        'output_size': 1408,\n",
    "    },\n",
    "    'efficientnetb3': {\n",
    "        'resolution': 300,\n",
    "        'output_size': 1536,\n",
    "    },\n",
    "    'efficientnetb4': {\n",
    "        'resolution': 380,\n",
    "        'output_size': 1792,\n",
    "    },\n",
    "    'efficientnetb5': {\n",
    "        'resolution': 456,\n",
    "        'output_size': 2048,\n",
    "    },\n",
    "    'efficientnetb6': {\n",
    "        'resolution': 528,\n",
    "        'output_size': 2304,\n",
    "    },\n",
    "    'efficientnetb7': {\n",
    "        'resolution': 600,\n",
    "        'output_size': 2560,\n",
    "    },\n",
    "}\n",
    "INPUT_SHAPE = (CONF[MODEL]['resolution'], CONF[MODEL]['resolution'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59513336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=11014\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      " 5   target       34250 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.csv\", engine=\"c\", low_memory=False)\n",
    "train[\"target\"] = mylib.target_label(train)\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "train[\"label_group\"] = le.fit_transform(train['label_group'])\n",
    "n_classes=len(le.classes_)\n",
    "print(f\"n_classes={n_classes}\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e562b629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "      <td>7572</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>[train_2288590299, train_3803689425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi</td>\n",
       "      <td>10509</td>\n",
       "      <td>[train_2406599165, train_3342059966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0                                                                           Paper Bag Victoria Secret   \n",
       "1                                        Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE   \n",
       "2                                                         Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi   \n",
       "4                                                                   Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "\n",
       "   label_group                                target  \n",
       "0          666   [train_129225211, train_2278313361]  \n",
       "1         7572  [train_3386243561, train_3423213080]  \n",
       "2         6172  [train_2288590299, train_3803689425]  \n",
       "3        10509  [train_2406599165, train_3342059966]  \n",
       "4         9425   [train_3369186413, train_921438619]  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0a57dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_gen(\n",
    "    dataframe,\n",
    "    directory,\n",
    "    target_size,\n",
    "    batch_size,\n",
    "    mode,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label_group\"\n",
    "):\n",
    "    dtype = np.float32\n",
    "    rescale = 1./255\n",
    "    interpolation = \"nearest\"\n",
    "    shuffle = False\n",
    "    idg = keras.preprocessing.image.ImageDataGenerator(rescale=rescale, dtype=dtype)\n",
    "    if mode == \"train\":\n",
    "        shuffle = True\n",
    "        idg = keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            dtype=dtype\n",
    "        )\n",
    "    return idg.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        directory=directory,\n",
    "        target_size=target_size,\n",
    "        color_mode=color_mode,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        class_mode=class_mode,\n",
    "        interpolation=interpolation,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e769ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22832 validated image filenames.\n",
      "Found 11418 validated image filenames.\n",
      "Found 22834 validated image filenames.\n",
      "Found 11416 validated image filenames.\n",
      "Found 22834 validated image filenames.\n",
      "Found 11416 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "spl = sklearn.model_selection.GroupKFold(n_splits=3)\n",
    "x = train\n",
    "y = train[\"label_group\"]\n",
    "groups = train[\"label_group\"]\n",
    "for ti, vi in spl.split(x, y, groups):\n",
    "    val = train.iloc[vi]\n",
    "    train_gen = _data_gen(\n",
    "        dataframe=train.iloc[ti],\n",
    "        directory=\"input/train_images\",\n",
    "        target_size=INPUT_SHAPE[:2],\n",
    "        batch_size=32,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    val_gen = _data_gen(\n",
    "        dataframe=train.iloc[vi],\n",
    "        directory=\"input/train_images\",\n",
    "        target_size=INPUT_SHAPE[:2],\n",
    "        batch_size=32,\n",
    "        mode=\"val\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "65562682",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3d9e3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model(\n",
    "    pretrained,\n",
    "    n_classes: int,\n",
    "    lr: float,\n",
    "    input_shape: Tuple[int, int, int],\n",
    "    dtype=np.float32\n",
    "):\n",
    "    pretrained.trainable = False\n",
    "    #kernel_initializer = keras.initializers.he_normal()\n",
    "    #kernel_regularizer = keras.regularizers.l2(0.01)\n",
    "    image_input = keras.layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    label_input = keras.layers.Input(shape=(), name=\"label_input\")\n",
    "    x = pretrained(image_input)\n",
    "    x = ArcMarginProduct(\n",
    "        n_classes=n_classes, \n",
    "        s=30, \n",
    "        m=0.5, \n",
    "        name='head/arc_margin', \n",
    "        dtype=dtype\n",
    "    )([x, label_input])\n",
    "    output = tf.keras.layers.Softmax(dtype=dtype)(x)\n",
    "    model = tf.keras.models.Model(inputs = [image_input, label_input], outputs = [output])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "    sca = keras.metrics.SparseCategoricalAccuracy()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[sca])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3b61bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnetb3 (Functional)     (None, 1536)         10783535    image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "label_input (InputLayer)        [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head/arc_margin (ArcMarginProdu (None, 11014)        16917504    efficientnetb3[0][0]             \n",
      "                                                                 label_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)             (None, 11014)        0           head/arc_margin[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 27,701,039\n",
      "Trainable params: 16,917,504\n",
      "Non-trainable params: 10,783,535\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained = keras.applications.EfficientNetB3(\n",
    "    include_top=False,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    pooling=\"max\",\n",
    "    weights=\"pretrained/efficientnet/efficientnetb3_notop.h5\"\n",
    ")\n",
    "model = _model(\n",
    "    pretrained=pretrained,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    n_classes=n_classes,\n",
    "    lr=1e-3,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12539056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObjective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        splitter,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        patience: int,\n",
    "        hidden_layer_sizes: List[int],\n",
    "        job_dir: str,\n",
    "        dropout: Tuple[float, float],\n",
    "        lr: Tuple[float, float],\n",
    "        groups=None,\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.splitter = splitter\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.job_dir = job_dir\n",
    "        self.groups = groups\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.history: List[Dict[str, Union[str, int, float]]] = []\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        hist = {\n",
    "            \"trial_id\": trial.number,\n",
    "            \"dropout\": trial.suggest_uniform(\n",
    "                \"dropout\", self.dropout[0], self.dropout[1]\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\n",
    "                \"learning_rate\", self.lr[0], self.lr[1]\n",
    "            ),\n",
    "        }\n",
    "        scores = []\n",
    "        for fold, (ti, vi) in enumerate(\n",
    "            self.splitter.split(self.X, self.y, groups=self.groups)\n",
    "        ):\n",
    "            x_train, y_train = self.X[ti], self.y[ti]\n",
    "            x_val, y_val = self.X[vi], self.y[vi]\n",
    "            model = _model(\n",
    "                input_dims=x_train.shape[1],\n",
    "                dropout=hist[\"dropout\"],\n",
    "                lr=hist[\"learning_rate\"],\n",
    "                hidden_layer_sizes=self.hidden_layer_sizes,\n",
    "            )\n",
    "            model.summary()\n",
    "            directory = f\"{self.job_dir}/trial_{hist['trial_id']}/fold_{fold}\"\n",
    "            model.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=self.epochs,\n",
    "                batch_size=self.batch_size,\n",
    "                validation_data=(x_val, y_val),\n",
    "                callbacks=_callbacks(directory, es_patience=self.patience,),\n",
    "            )\n",
    "            y_pred = model.predict(x_val, batch_size=self.batch_size)\n",
    "            score = metrics.mean_squared_error(y_val, y_pred, squared=False)\n",
    "            log.info(f\"score={score:.4f}, fold={fold}, trial={hist['trial_id']}\")\n",
    "            hist[f\"fold_{fold}_score\"] = score\n",
    "            scores.append(score)\n",
    "            del model\n",
    "            gc.collect()\n",
    "        hist[\"score_mean\"] = np.mean(scores)\n",
    "        hist[\"score_std\"] = np.std(scores)\n",
    "        hist[\"score_worst\"] = max(scores)\n",
    "        self.history.append(hist)\n",
    "        return hist[\"score_worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2976cc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8512c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
