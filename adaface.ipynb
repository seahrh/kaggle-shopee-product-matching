{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1ec5c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scml\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14f0166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scml.seed_everything()\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba86c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'efficientnetb3'\n",
    "CONF = {\n",
    "    'efficientnetb0': {\n",
    "        'resolution': 224,\n",
    "        'output_size': 1280,\n",
    "    },\n",
    "    'efficientnetb1': {\n",
    "        'resolution': 240,\n",
    "        'output_size': 0,\n",
    "    },\n",
    "    'efficientnetb2': {\n",
    "        'resolution': 260,\n",
    "        'output_size': 1408,\n",
    "    },\n",
    "    'efficientnetb3': {\n",
    "        'resolution': 300,\n",
    "        'output_size': 1536,\n",
    "    },\n",
    "    'efficientnetb4': {\n",
    "        'resolution': 380,\n",
    "        'output_size': 1792,\n",
    "    },\n",
    "    'efficientnetb5': {\n",
    "        'resolution': 456,\n",
    "        'output_size': 2048,\n",
    "    },\n",
    "    'efficientnetb6': {\n",
    "        'resolution': 528,\n",
    "        'output_size': 2304,\n",
    "    },\n",
    "    'efficientnetb7': {\n",
    "        'resolution': 600,\n",
    "        'output_size': 2560,\n",
    "    },\n",
    "}\n",
    "INPUT_SHAPE = (CONF[MODEL]['resolution'], CONF[MODEL]['resolution'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b0abc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes=11014\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      " 5   target       34250 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.csv\", engine=\"c\", low_memory=False)\n",
    "train[\"target\"] = mylib.target_label(train)\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "train[\"label_group\"] = le.fit_transform(train['label_group'])\n",
    "print(f\"n_classes={len(le.classes_)}\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0144d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "      <td>7572</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>[train_2288590299, train_3803689425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi</td>\n",
       "      <td>10509</td>\n",
       "      <td>[train_2406599165, train_3342059966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0                                                                           Paper Bag Victoria Secret   \n",
       "1                                        Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE   \n",
       "2                                                         Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi   \n",
       "4                                                                   Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "\n",
       "   label_group                                target  \n",
       "0          666   [train_129225211, train_2278313361]  \n",
       "1         7572  [train_3386243561, train_3423213080]  \n",
       "2         6172  [train_2288590299, train_3803689425]  \n",
       "3        10509  [train_2406599165, train_3342059966]  \n",
       "4         9425   [train_3369186413, train_921438619]  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "593f7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_gen(\n",
    "    dataframe,\n",
    "    directory,\n",
    "    target_size,\n",
    "    batch_size,\n",
    "    mode,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"raw\",\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label_group\"\n",
    "):\n",
    "    dtype = np.float32\n",
    "    rescale = 1./255\n",
    "    shuffle = False\n",
    "    idg = keras.preprocessing.image.ImageDataGenerator(rescale=rescale, dtype=dtype)\n",
    "    if mode == \"train\":\n",
    "        shuffle = True\n",
    "        idg = keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            dtype=dtype\n",
    "        )\n",
    "    return idg.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        directory=directory,\n",
    "        target_size=target_size,\n",
    "        color_mode=color_mode,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        class_mode=class_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b006d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22832 validated image filenames.\n",
      "Found 11418 validated image filenames.\n",
      "Found 22834 validated image filenames.\n",
      "Found 11416 validated image filenames.\n",
      "Found 22834 validated image filenames.\n",
      "Found 11416 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "spl = sklearn.model_selection.GroupKFold(n_splits=3)\n",
    "x = train\n",
    "y = train[\"label_group\"]\n",
    "groups = train[\"label_group\"]\n",
    "for ti, vi in spl.split(x, y, groups):\n",
    "    val = train.iloc[vi]\n",
    "    train_gen = _data_gen(\n",
    "        dataframe=train.iloc[ti],\n",
    "        directory=\"input/train_images\",\n",
    "        target_size=INPUT_SHAPE[:2],\n",
    "        batch_size=32,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    val_gen = _data_gen(\n",
    "        dataframe=train.iloc[vi],\n",
    "        directory=\"input/train_images\",\n",
    "        target_size=INPUT_SHAPE[:2],\n",
    "        batch_size=32,\n",
    "        mode=\"val\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model(\n",
    "    pretrained,\n",
    "    dropout: float,\n",
    "    lr: float,\n",
    "    pooling: str,\n",
    "    hidden_layer_sizes: List[int]\n",
    "):\n",
    "    pretrained.trainable = False\n",
    "    kernel_initializer = keras.initializers.he_normal()\n",
    "    kernel_regularizer = keras.regularizers.l2(0.01)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(pretrained)\n",
    "    for i in range(len(hidden_layer_sizes)):\n",
    "        model.add(keras.layers.LayerNormalization())\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                hidden_layer_sizes[i],\n",
    "                activation=\"relu\",\n",
    "                kernel_initializer=kernel_initializer,\n",
    "                kernel_regularizer=kernel_regularizer,\n",
    "                name=f\"Dense{i + 1}\",\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(len(TARGET), name=\"output\"))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "    rmse = keras.metrics.SparseCategoricalAccuracy()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[rmse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObjective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        splitter,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        patience: int,\n",
    "        hidden_layer_sizes: List[int],\n",
    "        job_dir: str,\n",
    "        dropout: Tuple[float, float],\n",
    "        lr: Tuple[float, float],\n",
    "        groups=None,\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.splitter = splitter\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.job_dir = job_dir\n",
    "        self.groups = groups\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.history: List[Dict[str, Union[str, int, float]]] = []\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        hist = {\n",
    "            \"trial_id\": trial.number,\n",
    "            \"dropout\": trial.suggest_uniform(\n",
    "                \"dropout\", self.dropout[0], self.dropout[1]\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\n",
    "                \"learning_rate\", self.lr[0], self.lr[1]\n",
    "            ),\n",
    "        }\n",
    "        scores = []\n",
    "        for fold, (ti, vi) in enumerate(\n",
    "            self.splitter.split(self.X, self.y, groups=self.groups)\n",
    "        ):\n",
    "            x_train, y_train = self.X[ti], self.y[ti]\n",
    "            x_val, y_val = self.X[vi], self.y[vi]\n",
    "            model = _model(\n",
    "                input_dims=x_train.shape[1],\n",
    "                dropout=hist[\"dropout\"],\n",
    "                lr=hist[\"learning_rate\"],\n",
    "                hidden_layer_sizes=self.hidden_layer_sizes,\n",
    "            )\n",
    "            model.summary()\n",
    "            directory = f\"{self.job_dir}/trial_{hist['trial_id']}/fold_{fold}\"\n",
    "            model.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=self.epochs,\n",
    "                batch_size=self.batch_size,\n",
    "                validation_data=(x_val, y_val),\n",
    "                callbacks=_callbacks(directory, es_patience=self.patience,),\n",
    "            )\n",
    "            y_pred = model.predict(x_val, batch_size=self.batch_size)\n",
    "            score = metrics.mean_squared_error(y_val, y_pred, squared=False)\n",
    "            log.info(f\"score={score:.4f}, fold={fold}, trial={hist['trial_id']}\")\n",
    "            hist[f\"fold_{fold}_score\"] = score\n",
    "            scores.append(score)\n",
    "            del model\n",
    "            gc.collect()\n",
    "        hist[\"score_mean\"] = np.mean(scores)\n",
    "        hist[\"score_std\"] = np.std(scores)\n",
    "        hist[\"score_worst\"] = max(scores)\n",
    "        self.history.append(hist)\n",
    "        return hist[\"score_worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "092dba0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = keras.applications.EfficientNetB3(\n",
    "    include_top=False,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    pooling=\"max\",\n",
    "    weights=\"pretrained/efficientnet/efficientnetb3_notop.h5\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
