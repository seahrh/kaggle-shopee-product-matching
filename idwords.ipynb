{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b2ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pankun/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')  # required for word_tokenize\n",
    "import tqdm\n",
    "from scml.nlp import to_ascii_str, expand_contractions, strip_punctuation, count_digit\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09c9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85287734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.csv\", engine=\"c\", low_memory=False)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cee7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for t in train.itertuples():\n",
    "    title = getattr(t, \"title\")\n",
    "    text = f\"{text} {title}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b312193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.45 s, sys: 15.6 ms, total: 3.47 s\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = text.lower()\n",
    "text = to_ascii_str(text)\n",
    "text = expand_contractions(text)\n",
    "text = strip_punctuation(text)\n",
    "text = nltk.word_tokenize(text)\n",
    "text = [w for w in text if count_digit(w) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86936825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=['paper', 'bag', 'victoria', 'secret', 'double', 'tape', 'vhb', 'mm', 'x', 'm', 'original', 'double', 'foam', 'tape', 'maling', 'tts', 'canned', 'pork', 'luncheon', 'meat', 'gr', 'daster', 'batik', 'lengan', 'pendek', 'motif', 'acak', 'campur', 'leher', 'kancing', 'batik', 'karakter', 'alhadi', 'nescafe', 'latte', 'celana', 'wanita', 'bb', 'kgharem', 'wanita', 'bisa', 'cod', 'jubah', 'anak', 'size', 'thn', 'kulot', 'plisket', 'salur', 'candy', 'plisket', 'wish', 'kulot', 'premium', 'kulot', 'pelangi', 'premiumhieka', 'kulot', 'logu', 'tempelan', 'kulkas', 'magnet', 'angka', 'tempelan', 'angka', 'magnet', 'big', 'sale', 'sepatu', 'pantofel', 'kulit', 'keren', 'kerja', 'kantor', 'laki', 'pria', 'cowok', 'dinas', 'resmi', 'formal', 'pesta', 'kickers', 'atasan', 'rajut', 'wanita', 'lisdia', 'sweater', 'pashmina', 'kusut', 'rawis', 'polos', 'crinkle', 'shawl', 'murah', 'banget', 'pashmina', 'kusut', 'rawis', 'polos', 'crinkle']\n"
     ]
    }
   ],
   "source": [
    "print(f\"text={text[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d071b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/pankun/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to /home/pankun/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /home/pankun/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to /home/pankun/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_words)=14955\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('reuters')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('webtext')\n",
    "from nltk.corpus import brown, reuters, gutenberg, webtext\n",
    "en_words = set(w.lower() for w in brown.words())\n",
    "en_words |= set(w.lower() for w in reuters.words())\n",
    "en_words |= set(w.lower() for w in gutenberg.words())\n",
    "en_words |= set(w.lower() for w in webtext.words())\n",
    "words = set(text)\n",
    "id_words = words - en_words\n",
    "print(f\"len(id_words)={len(id_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dde4554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 14955 samples and 140662 outcomes>\n"
     ]
    }
   ],
   "source": [
    "tmp = [w for w in text if w in id_words]\n",
    "fd = nltk.FreqDist(tmp)\n",
    "print(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77040ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wanita', 1844), ('murah', 1418), ('tas', 1238), ('pria', 1139), ('bayi', 1107), ('untuk', 1075), ('isi', 875), ('tangan', 864), ('kaos', 823), ('warna', 821), ('baju', 807), ('sepatu', 802), ('celana', 751), ('alat', 717), ('bahan', 701), ('polos', 683), ('rambut', 668), ('termurah', 582), ('bisa', 546), ('lampu', 534), ('mainan', 527), ('bpom', 501), ('hijab', 486), ('panjang', 478), ('sarung', 468), ('usb', 465), ('kain', 461), ('karakter', 454), ('sabun', 440), ('paket', 439), ('plastik', 433), ('hitam', 431), ('tempat', 422), ('jumbo', 410), ('gamis', 407), ('botol', 404), ('putih', 402), ('dengan', 401), ('kaki', 385), ('wajah', 384), ('jilbab', 383), ('grosir', 381), ('dompet', 373), ('tali', 364), ('pendek', 363), ('serbaguna', 348), ('kabel', 341), ('iphone', 338), ('buku', 335), ('tahun', 328), ('kotak', 323), ('pembersih', 311), ('lipat', 310), ('minyak', 309), ('bunga', 302), ('selempang', 299), ('kulit', 296), ('oppo', 292), ('mukena', 287), ('asli', 286), ('katun', 284), ('silikon', 283), ('matte', 281), ('xiaomi', 277), ('topi', 277), ('terbaru', 276), ('dewasa', 275), ('instan', 275), ('madu', 275), ('obat', 273), ('mandi', 271), ('dinding', 267), ('terlaris', 266), ('susu', 265), ('kaca', 260), ('dapur', 258), ('kacamata', 254), ('ukuran', 253), ('lengan', 251), ('resmi', 251), ('mata', 251), ('wardah', 245), ('koko', 245), ('lucu', 245), ('garansi', 244), ('kuas', 244), ('gantungan', 243), ('cuci', 242), ('joyko', 239), ('besar', 238), ('perempuan', 235), ('earphone', 231), ('setelan', 228), ('sepeda', 228), ('dalam', 221), ('acne', 221), ('ikat', 221), ('tanpa', 221), ('kecil', 220), ('rajut', 217)]\n"
     ]
    }
   ],
   "source": [
    "mc = fd.most_common()\n",
    "print(mc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d8dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/idwords.tsv\", \"w\") as f:\n",
    "    for t in mc:\n",
    "        f.write(f\"{t[0]}\\t{t[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d0d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [w for w in text if w in en_words]\n",
    "fd = nltk.FreqDist(tmp)\n",
    "mc = fd.most_common()\n",
    "with open(\"output/enwords.tsv\", \"w\") as f:\n",
    "    for t in mc:\n",
    "        f.write(f\"{t[0]}\\t{t[1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
