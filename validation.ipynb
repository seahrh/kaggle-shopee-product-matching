{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47f2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import py\n",
    "import mylib\n",
    "import cv2 as cv\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List, Dict, Set, Tuple\n",
    "from scml.nlp import strip_punctuation, to_ascii_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63c34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OMP_THREAD_LIMIT\"] = \"1\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd64e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34250 entries, 0 to 34249\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   posting_id   34250 non-null  object\n",
      " 1   image        34250 non-null  object\n",
      " 2   image_phash  34250 non-null  object\n",
      " 3   title        34250 non-null  object\n",
      " 4   label_group  34250 non-null  int64 \n",
      " 5   target       34250 non-null  object\n",
      " 6   image_path   34250 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.csv\", engine=\"c\", low_memory=False)\n",
    "train[\"target\"] = mylib.target_label(train)\n",
    "train[\"image_path\"] = \"input/train_images/\" + train[\"image\"]\n",
    "posting_ids = train[\"posting_id\"].tolist()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cf5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ab20a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 1280)              4049571   \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 1280)              2560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1280)              1639680   \n",
      "_________________________________________________________________\n",
      "embedding_output (LayerNorma (None, 1280)              2560      \n",
      "=================================================================\n",
      "Total params: 5,694,371\n",
      "Trainable params: 1,644,800\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"models/eb0_arc_20210501_0030\"\n",
    "m0 = keras.models.load_model(f\"{model_dir}/trial_0/fold_0/model.h5\", custom_objects={\"ArcMarginProduct\": ArcMarginProduct})\n",
    "m0 = keras.models.Model(inputs=m0.input[0], outputs=m0.get_layer(\"embedding_output\").output)\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25766c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 1280)              4049571   \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 1280)              2560      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1280)              1639680   \n",
      "_________________________________________________________________\n",
      "embedding_output (LayerNorma (None, 1280)              2560      \n",
      "=================================================================\n",
      "Total params: 5,694,371\n",
      "Trainable params: 1,644,800\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1 = keras.models.load_model(f\"{model_dir}/trial_0/fold_1/model.h5\", custom_objects={\"ArcMarginProduct\": ArcMarginProduct})\n",
    "m1 = keras.models.Model(inputs=m1.input[0], outputs=m1.get_layer(\"embedding_output\").output)\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17bfa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 1280)              4049571   \n",
      "_________________________________________________________________\n",
      "layer_normalization_3 (Layer (None, 1280)              2560      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1280)              1639680   \n",
      "_________________________________________________________________\n",
      "embedding_output (LayerNorma (None, 1280)              2560      \n",
      "=================================================================\n",
      "Total params: 5,694,371\n",
      "Trainable params: 1,644,800\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2 = keras.models.load_model(f\"{model_dir}/trial_0/fold_2/model.h5\", custom_objects={\"ArcMarginProduct\": ArcMarginProduct})\n",
    "m2 = keras.models.Model(inputs=m2.input[0], outputs=m2.get_layer(\"embedding_output\").output)\n",
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eedf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34250 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "idg = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    data_format=\"channels_last\",\n",
    "    dtype=np.float32\n",
    ")\n",
    "data = idg.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"label_group\",\n",
    "    directory=\"input/train_images\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "y0 = m0.predict(data, verbose=1)\n",
    "y1 = m1.predict(data, verbose=1)\n",
    "y2 = m2.predict(data, verbose=1)\n",
    "assert y0.shape == y1.shape == y2.shape\n",
    "print(f\"y0.shape={y0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(y0)):\n",
    "    a = np.vstack((y0[i], y1[i], y2[i]))\n",
    "    m = np.mean(a, axis=0)\n",
    "    res.append(m)\n",
    "em = np.array(res, dtype=np.float32)\n",
    "assert y0.shape == em.shape\n",
    "print(f\"em.shape={em.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "threshold = 0.5\n",
    "nn = NearestNeighbors(\n",
    "    n_neighbors=min(49, len(posting_ids) - 1), metric=\"euclidean\"\n",
    ")\n",
    "nn.fit(em)\n",
    "distances, indices = nn.kneighbors()\n",
    "res: List[List[str]] = [[] for _ in range(len(indices))]\n",
    "for i in range(len(indices)):\n",
    "    for j in range(len(indices[0])):\n",
    "        if distances[i][j] > threshold:\n",
    "            break\n",
    "        res[i].append(posting_ids[indices[i][j]])\n",
    "train[\"image_matches\"] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f4909",
   "metadata": {},
   "source": [
    "th=.25, f1=.586\n",
    "th=.30, f1=.586\n",
    "th=.35, f1=.587\n",
    "th=.40, f1=.583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356175a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train[\"phash_matches\"] = mylib.phash_matches(train, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train[\"title_p\"] = train.apply(mylib.preprocess(\"title\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "st_name = \"stsb-distilbert-base\"\n",
    "#st_name = \"paraphrase-distilroberta-base-v1\"\n",
    "#st_name = \"paraphrase-xlm-r-multilingual-v1\"\n",
    "train[\"title_matches\"] = mylib.sbert_matches(\n",
    "    model_path=f\"pretrained/sentence-transformers/{st_name}\",\n",
    "    sentences=train[\"title_p\"].tolist(),\n",
    "    posting_ids=posting_ids,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be017000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_dilate(img):\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img = cv.erode(img, kernel, iterations=1)\n",
    "    img = cv.dilate(img, kernel, iterations=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def image_to_text(img_path, mode: str, timeout: float, neighbours: int=41, psm: int=3) -> Optional[str]:\n",
    "    config = f\"--psm {psm}\"\n",
    "    s1, s2 = None, None\n",
    "    img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "    #img = cv.resize(img, None, fx=0.5, fy=0.5, interpolation=cv.INTER_AREA)\n",
    "    img = cv.medianBlur(img, 3)\n",
    "    if mode == \"binary_inverted\" or mode == \"binary\":\n",
    "        th = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, neighbours, 2)\n",
    "        th = erode_dilate(th)\n",
    "        try:\n",
    "            s1 = pytesseract.image_to_string(th, timeout=timeout, config=config)\n",
    "        except:\n",
    "            s1 = None\n",
    "    if mode == \"binary_inverted\" or mode == \"inverted\":\n",
    "        th = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, neighbours, 2)\n",
    "        th = erode_dilate(th)\n",
    "        try:\n",
    "            s2 = pytesseract.image_to_string(th, timeout=timeout, config=config)\n",
    "        except:\n",
    "            s2 = None\n",
    "    if s1 is None and s2 is None:\n",
    "        return None\n",
    "    tokens = []\n",
    "    if s1 is not None:\n",
    "        s1 = to_ascii_str(s1)\n",
    "        s1 = strip_punctuation(s1)\n",
    "        tokens += s1.split()\n",
    "    if s2 is not None:\n",
    "        s2 = to_ascii_str(s2)\n",
    "        s2 = strip_punctuation(s2)\n",
    "        tokens += s2.split()\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR = False\n",
    "if OCR:\n",
    "    res = []\n",
    "    n_timeout = 0\n",
    "    for t in tqdm(train.itertuples()):\n",
    "        img_path = getattr(t, \"image_path\")\n",
    "        s = image_to_text(img_path, mode=\"inverted\", timeout=0.4, neighbours=41, psm=11)\n",
    "        if s is None:\n",
    "            s = \"\"\n",
    "            n_timeout += 1\n",
    "        res.append(s)\n",
    "    print(f\"n_timeout={n_timeout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OCR:\n",
    "    train[\"itext\"] = res\n",
    "    train[\"text\"] = train[\"title\"] + \" \" + train[\"itext\"]\n",
    "    cols = [\"text\", \"itext\", \"title\"]\n",
    "    train[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if OCR:\n",
    "    train[\"text_p\"] = train.apply(mylib.preprocess(\"text\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ba74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OCR:\n",
    "    st_name = \"stsb-distilbert-base\"\n",
    "    #st_name = \"paraphrase-distilroberta-base-v1\"\n",
    "    #st_name = \"paraphrase-xlm-r-multilingual-v1\"\n",
    "    train[\"text_matches\"] = mylib.sbert_matches(\n",
    "        model_path=f\"pretrained/sentence-transformers/{st_name}\",\n",
    "        sentences=train[\"text_p\"].tolist(),\n",
    "        posting_ids=posting_ids,\n",
    "        threshold=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b834c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = [\"phash_matches\", \"title_matches\", \"image_matches\"]\n",
    "if OCR:\n",
    "    fs.append(\"text_matches\")\n",
    "train[\"matches\"] = train.apply(mylib.combine_as_list(fs), axis=1)\n",
    "train[\"f1\"] = train.apply(mylib.metric_per_row(\"matches\"), axis=1)\n",
    "print(f\"Combined score={train.f1.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c679a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [\n",
    "    {\n",
    "        \"score\": 0.674,\n",
    "        \"phash_threshold\": 0.3,\n",
    "        \"title_threshold\": 0.5,\n",
    "        \"text_threshold\": 0.5,\n",
    "        \"ocr_threshold\": \"inverted\",\n",
    "        \"ocr_timeout\": 0.4,\n",
    "        \"ocr_neighbours\": 41,\n",
    "        \"ocr_psm\": 11\n",
    "    },\n",
    "    {\n",
    "        \"score\": 0.674,\n",
    "        \"phash_threshold\": 0.3,\n",
    "        \"title_threshold\": 0.5,\n",
    "        \"text_threshold\": 0.5,\n",
    "        \"ocr_threshold\": \"binary\",\n",
    "        \"ocr_timeout\": 0.4,\n",
    "        \"ocr_neighbours\": 41,\n",
    "        \"ocr_psm\": 11\n",
    "    },\n",
    "    {\n",
    "        \"score\": 0.674,\n",
    "        \"phash_threshold\": 0.3,\n",
    "        \"title_threshold\": 0.5,\n",
    "        \"text_threshold\": None,\n",
    "        \"ocr_threshold\": None,\n",
    "        \"ocr_timeout\": None,\n",
    "        \"ocr_neighbours\": None,\n",
    "        \"ocr_psm\": None\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame.from_records(res)\n",
    "df.sort_values(\"score\", ascending=False, inplace=True, ignore_index=True)\n",
    "df.head(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"f1\", \"target\", \"matches\"] + fs\n",
    "train[cols].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b51767",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"f1\", ascending=True, inplace=True, ignore_index=True)\n",
    "train[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62c873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
